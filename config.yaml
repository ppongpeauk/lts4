# Concert2Studio Configuration
# All hyperparameters, paths, and toggle flags

# Data Configuration
data:
  data_dir: "./data"
  sample_rate: 48000  # Use 48kHz for better audio quality and noise reduction
  bit_depth: 24
  train_split: 0.8
  val_split: 0.2
  random_seed: 42
  use_synthetic: true  # Enable synthetic data for better generalization

# Audio Processing (optimized for 48kHz)
audio:
  segment_length: 2.0  # Longer segments for better context
  n_fft: 1024  # Larger FFT for better frequency resolution
  hop_length: 256
  win_length: 1024
  window: "hann"

# Model Architecture
model:
  # Spectrogram U-Net (optimized for small dataset + stereo)
  unet:
    in_channels: 513  # Frequency bins for 1024 FFT (1024//2 + 1)
    base_channels: 8  # Increased capacity
    max_channels: 64  # Reasonable capacity
    n_blocks: 3  # More blocks for better learning
    dilations: [1, 2, 4]  # Multi-scale receptive fields
    use_attention: true  # Keep attention for better quality
    attention_heads: 2
    dropout: 0.3  # Moderate regularization
    use_stereo: true  # Enable stereo processing

  # Enhanced UnivNet Vocoder (with noise reduction)
  use_vocoder: true  # Keep vocoder for quality enhancement
  vocoder:
    model_name: "univnet-c32"
    pretrained: false  # Train from scratch for better fit
    freeze_epochs: 5
    use_stereo: true  # Enable stereo output

# Training Configuration (research-optimized for small dataset)
training:
  batch_size: 1  # Small but efficient batches
  num_epochs: 50  # More training with better regularization
  learning_rate: 5e-5  # Standard learning rate
  weight_decay: 1e-4  # Moderate L2 regularization
  beta1: 0.9  # Standard Adam parameters
  beta2: 0.999
  warmup_steps: 100  # Proper warmup for stability
  early_stopping_patience: 10  # More patience with better model
  gradient_accumulation_steps: 4  # Effective batch size 8
  max_grad_norm: 1.0  # Standard gradient clipping
  scheduler: "cosine"  # Cosine annealing for stability

# Loss Configuration (simplified for stability)
loss:
  l1_weight: 0.7  # Dominant reconstruction loss
  multires_stft_weight: 0.2  # Reduced spectral loss
  vggish_weight: 0.0  # Disabled heavy perceptual loss
  adversarial_weight: 0.0  # Disabled for stability

  # Multi-resolution STFT scales (reduced for stability)
  stft_scales: [512, 1024, 2048]

# Data Augmentation (research-based for small datasets)
augmentation:
  gain_jitter_db: 3.0  # Moderate variation
  gain_jitter_prob: 0.8
  pink_noise_prob: 0.3  # Controlled noise augmentation
  pink_noise_level: -40  # Subtle noise injection
  time_shift_ms: 50  # Moderate time variation
  time_shift_prob: 0.7  # Frequent but not always
  # Advanced augmentation techniques from research
  mixup_prob: 0.2  # Mix samples for better generalization
  mixup_alpha: 0.4  # Conservative mixing
  spec_augment_prob: 0.5  # Spectrogram augmentation
  freq_mask_prob: 0.3
  time_mask_prob: 0.3

# Checkpointing and Logging
checkpoint:
  save_interval_minutes: 15
  save_interval_steps: 500
  max_checkpoints: 5
  resume_from: null  # path to checkpoint to resume from

# Hardware Configuration
hardware:
  num_workers: 16
  pin_memory: true
  persistent_workers: true
  compile_model: false  # Disabled to avoid CUDA compilation issues
  channels_last: false  # Not applicable to audio models

# Paths
paths:
  output_dir: "./outputs"
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
