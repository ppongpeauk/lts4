# Concert2Studio Configuration
# All hyperparameters, paths, and toggle flags

# Data Configuration
data:
  data_dir: "./data"
  sample_rate: 48000  # Use 48kHz for better audio quality and noise reduction
  bit_depth: 24
  train_split: 0.8
  val_split: 0.2
  random_seed: 42
  use_synthetic: true  # Enable synthetic data for better generalization

# Audio Processing (optimized for 48kHz)
audio:
  segment_length: 2.0  # Longer segments for better context
  n_fft: 1024  # Larger FFT for better frequency resolution
  hop_length: 256
  win_length: 1024
  window: "hann"

# Model Architecture
model:
  # Spectrogram U-Net (optimized for small dataset + stereo)
  unet:
    in_channels: 513  # Frequency bins for 1024 FFT (1024//2 + 1)
    base_channels: 16  # Increased capacity
    max_channels: 128  # Reasonable capacity
    n_blocks: 3  # More blocks for better learning
    dilations: [1, 2, 4]  # Multi-scale receptive fields
    use_attention: true  # Keep attention for better quality
    attention_heads: 2
    dropout: 0.3  # Moderate regularization
    use_stereo: true  # Enable stereo processing

  # Enhanced UnivNet Vocoder (with noise reduction)
  use_vocoder: true  # Keep vocoder for quality enhancement
  vocoder:
    model_name: "univnet-c32"
    pretrained: false  # Train from scratch for better fit
    freeze_epochs: 15  # Freeze longer to establish stable UNet first
    use_stereo: true  # Enable stereo output

# Training Configuration (research-optimized for small dataset)
training:
  batch_size: 2  # Small but efficient batches
  num_epochs: 50  # More training with better regularization
  learning_rate: 2e-5  # Much lower learning rate for stability
  weight_decay: 1e-4  # Reduced L2 regularization to prevent over-regularization
  beta1: 0.9  # Standard Adam parameters
  beta2: 0.999
  warmup_steps: 200  # Longer warmup for stability
  early_stopping_patience: 15  # More patience with unstable training
  gradient_accumulation_steps: 4  # Effective batch size 8
  max_grad_norm: 0.5  # Stricter gradient clipping
  scheduler: "linear"  # Linear decay instead of cosine for stability

# Loss Configuration (simplified for stability)
loss:
  l1_weight: 1.0  # Focus primarily on L1 reconstruction
  multires_stft_weight: 0.0  # Disable spectral loss initially for stability
  vggish_weight: 0.0  # Disabled heavy perceptual loss
  adversarial_weight: 0.0  # Disabled for stability

  # Multi-resolution STFT scales (reduced for stability)
  stft_scales: [512, 1024, 2048]

# Data Augmentation (research-based for small datasets)
augmentation:
  gain_jitter_db: 1.0  # Much reduced variation for stability
  gain_jitter_prob: 0.3  # Reduced probability
  pink_noise_prob: 0.1  # Minimal noise augmentation
  pink_noise_level: -50  # Even more subtle noise injection
  time_shift_ms: 20  # Reduced time variation
  time_shift_prob: 0.3  # Reduced probability
  # Advanced augmentation techniques from research
  mixup_prob: 0.0  # Disable mixup initially for stability
  mixup_alpha: 0.2  # Reduced mixing if enabled
  spec_augment_prob: 0.0  # Disable spectrogram augmentation initially
  freq_mask_prob: 0.1
  time_mask_prob: 0.1

# Checkpointing and Logging
checkpoint:
  save_interval_minutes: 15
  save_interval_steps: 500
  max_checkpoints: 5
  resume_from: null  # path to checkpoint to resume from

# Hardware Configuration
hardware:
  num_workers: 16
  pin_memory: true
  persistent_workers: true
  compile_model: false  # Disabled to avoid CUDA compilation issues
  channels_last: false  # Not applicable to audio models

# Paths
paths:
  output_dir: "./outputs"
  checkpoint_dir: "./checkpoints"
  log_dir: "./logs"
